---
title: "Species richness regression"
output: 
  html_document:
    toc: yes
    toc_float: true
    number_sections: true
bibliography: mgc.bib     
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

***

<div class="alert alert-info">
**RStudio project**

Open the RStudio project that we created in the first session. I recommend to use this RStudio project for the entire course and within the RStudio project create separate R scripts for each session. 

- Create a new empty R script by going to the tab "File", select "New File"  and then "R script"
- In the new R script, type `# Session a3: Species richness regression` and save the file in your folder "scripts" within your project folder, e.g. as "a3_RichnessRegression.R"
</div>

In the last session, we have explored the species richness gradients in UK breeding birds. We continue with these and now try to explain statistically which environmental variables are driving species richness. 

# Data on breeding bird richness

We will work with the dataset of British breeding and wintering birds from @Gillings2019, more specifically with the bird records from Britain at 10 km resolution during the breeding seasons 2008-2011. The original data are available through the British Trust of Ornithology (www.bto.org; direct download [here](https://www.bto.org/sites/default/files/atlas_open_data_files.zip)). In the last session, we have already calculated species richness and extracted bioclimatic variables from worldclim for all Britain.

We can load the data into R and inspect them. 

```{r message=F, warning=F}
# We load the R object from last session (using the function load()) and assign it to a new object name (using the function get())
UK_birdrichness_clim <- get(load('data/UK_bird_richness_clim.RData'))

# Inspect the data
summary(UK_birdrichness_clim)
```

There seem to be some missing values in our data frame and we remove these as they could cause problems in modelling.
```{r}
UK_birdrichness_clim <- na.omit(UK_birdrichness_clim)
```
```{r eval=F, echo=F}
library(raster)
library(dismo)
clim <- stack('data/UK_bioclim.grd')

xy <- gridSample(UK_birdrichness_clim[,c("EASTING","NORTHING")], clim,chess='white')
sp_thinned <- merge(xy,UK_birdrichness_clim,by=c("EASTING","NORTHING"))

```

We map species richness.

```{r}
# Map species richness
library(raster)
plot(rasterFromXYZ(UK_birdrichness_clim[,c('EASTING','NORTHING','richness')]))
```

We had already plotted species-energy relationships. In the next step, we aim to describe these statistically.

```{r message=F, warning=F}
library(ggplot2)
library(ggpubr)

# Plot species-energy relationships
p1 <- ggplot(data = UK_birdrichness_clim, mapping = aes(x = bio10/10, y = richness)) + 
  geom_point() + 
  geom_smooth(method="loess") + 
  xlab('Summer temperature [Â°C]') + 
  ylab('Species richness')

p2 <- ggplot(data = UK_birdrichness_clim, mapping = aes(x = bio4, y = richness)) + 
  geom_point() + 
  geom_smooth(method="loess") + 
  xlab('Temperature seasonality') + 
  ylab('Species richness')

p3 <- ggplot(data = UK_birdrichness_clim, mapping = aes(x = bio12, y = richness)) + 
  geom_point() + 
  geom_smooth(method="loess") + 
  xlab('Annual precipitation [mm]') + 
  ylab('Species richness')

ggarrange(p1, p2, p3, ncol = 3)
```

# Richness regression

We will build regression models using Generalised Linear Models (GLMs).

## Generalised linear models (GLMs)

Why do we not simply use linear regression to fit our species-environment relationship? Well, strictly, ordinary least squares (OLS) linear regression is only valid if the response (or rather the error) is normally distributed and ranges ($-\infty,\infty$). OLS regression looks like this

$$E(Y|X)=\beta X+\epsilon$$

where $E(Y|X)$ is the *conditional mean*, meaning the expected value of the response $Y$ given the environmental predictors $X$ [@Hosmer2013]. $X$ is the matrix of predictors (including the intercept), $\beta$ are the coefficients for the predictors, and $\epsilon$ is the (normally distributed!) error term. $\beta X$ is referred to as the linear predictor.

When we want to predict species richness based on environment, then the conditional mean $E(Y|X)$ is a count and bounded ($0,\infty$). Thus, the assumptions of OLS regression are not met. GLMs are more flexible regression models that allow the response variable to follow other distributions. Similar to OLS regression, we also fit a linear predictor $\beta X$ and then relate this linear predictor to the mean of the response variable using a link function. The link function is used to transform the response to normality. In case of count data, we typically use the log link. The conditional mean is then given by:

$$E(Y|X) = \lambda (X) = e^{\beta X+\epsilon}$$

The log transformation is defined as:
$$g(X) 	= ln \left( \lambda (X) \right)	= \beta X+\epsilon$$

The trick is that the log, g(X), is now linear in its parameters, is continuous and may range ($-\infty,\infty$). GLMs with a log link are also called Poisson regression models. 

## GLMs in `R`

The `glm` function is contained in the R *stats* package. We need to specify a *formula* describing how the response should be related to the predictors, and the *data* specifying the data frame that contains the response and predictor variables, and a *family* argument specifying the type of response and the link function. In our case, we use the *log* link in the *poisson* family.

There are also several standard functions for exploring the models and model fit, e.g. `summary()` for printing a compact summary of the coefficients, residuals and deviance to the console. 

```{r}
# We first fit a GLM for the bio10 variable assuming a linear relationship:
m1 <- glm(richness ~ bio10, family="poisson", data= UK_birdrichness_clim)
	
# We can get a summary of the model:
summary(m1)	
```

As we expected from our initial plots, summer temperature (bio10) seems to have a significantly positive effect on bird species richness. 

## Deviance and AIC
Additional to the slope values, there are a few interesting metrics printed in the output called deviance $D$ and AIC (the *Akaike Information Criterion*). These metrics tell us something about how closely the model fits the observed data. Both are derived from the log-likelihood $L$ and are related through the following equation:

$$AIC = -2 \times L + 2 \times (p+1) = D + 2 \times (p+1)$$

where $p$ is the number of regression coefficients in the model. AIC thus takes into account model complexity. A closer fit to the data leads to higher log-likelihood and thus higher deviance and lower AIC. Yet, higher numbers of predictors in the model will increase the AIC. Thus, the AIC helps us taking into account the bias-variance trade-off that states that too few predictors or too simple models can lead to systematic bias while too many predictors or too complex models can lead to overfitting and low generalisation (high variance when predicting to independent data). 

We can also use the deviance to calculate the *Explained deviance* $D^2$, which is the amount of variation explained by the model compared to the null expectation:
$$D^2 = 1 - \frac{D(model)}{D(Null.model)}$$
The model output also provides the `Null deviance`, so we can easily calculate the explained deviance $D^2$.

<div class="alert alert-info">
_**Exercise:**_

What is the explained deviance of above model?
</div>

## More complex GLMs
We can also fit quadratic or higher polynomial terms (check `?poly`) and interactions between predictors:  
- the term `I()`indicates that a variable should be transformed before being used as predictor in the formula  
- `poly(x,n)` creates a polynomial of degree $n$: $x + x^2 + ... + x^n$  
- `x1:x2` creates a two-way interaction term between variables x1 and x2, the linear terms of x1 and x2 would have to be specified separately  
- `x1*x2` creates a two-way interaction term between variables x1 and x2 plus their linear terms  
- `x1*x2*x3` creates the linear terms of the three variables, all possible two-way interactions between these variables and the three-way interaction  

Try out different formulas:
```{r eval=F}
# Fit a quadratic relationship with bio10:
summary( glm(richness ~ bio10 + I(bio10^2), family="poisson", data= UK_birdrichness_clim))
	
# Or use the poly() function:
summary( glm(richness ~ poly(bio10,2) , family="poisson", data= UK_birdrichness_clim) )

# Fit two linear variables:
summary( glm(richness ~ bio10 + bio12, family="poisson", data= UK_birdrichness_clim) )

# Fit two variables with linear and quadratic terms:
summary( glm(richness ~ poly(bio10,2) + poly(bio12,2), family="poisson", data= UK_birdrichness_clim) )
```

<div class="alert alert-info">
_**Exercise:**_

Compare the AIC of these models. Which model is the best in terms of AIC?
</div>

## Collinearity and variable selection
GLMs (and many other statistical models) have problems to fit stable parameters if two or more predictor variables are highly correlated, resulting in so-called multicollinearity issues [@Dormann2013]. To avoid these problems here, we start by checking for multi-collinearity and by selecting an initical set of predictor variables. Then, we can fit our GLM including multiple predictors and with differently complex response shapes. This model can then be further simplified by removing "unimportant" predictors.

### Correlation among predictors
We first check for pairwise correlations among predictors. Generally, correlations below |r|<0.7 are considered unproblematic (or below |r|<0.5 as more conservative threshold).

```{r message=F}
library(corrplot)

# We first estimate a correlation matrix from the predictors. 
# We use Spearman rank correlation coefficient, as we do not know 
# whether all variables are normally distributed.
cor_mat <- cor(UK_birdrichness_clim[,-c(1:3)], method='spearman')

# We can visualise this correlation matrix. For better visibility, 
# we plot the correlation coefficients as percentages.
corrplot.mixed(cor_mat, tl.pos='lt', tl.cex=0.6, number.cex=0.5, addCoefasPercent=T)
```

Several predictor variables are highly correlated. One way to deal with this issue is to remove the "less important" variable from the highly correlated pairs. For this, we either need some prior knowledge on the system and strong assumptions, which predictors are more important, or we need to assess variable importance from the data.

### Variable selection: removing highly correlated variables
If no prior knowledge is available on the importance of different predictors, then @Dormann2013 suggest to assess univariate variable importance in terms of AIC (Akaike information criterion) or explained deviance. In practice, this means that we fit a GLM separately for each predictor, assess the importance and then rank the variables according to their univariate importance. Earlier, we already fitted GLMs with linear and quadratic terms and compared AIC. Which one was better?

However, it's getting a bit more complicated when we want to compare all variables. First, we need to identify all pairs of variables that have correlation |r|>0.7 and remove the less important variable. @Dormann2013 call this the *select07* method.

A `select07()` function is implemented in the package `mecofun` along with some other useful functions for the entire *MGC* module. We first have to install the package from the Univ. Potsdam gitlab:


```{r eval=F}
library(devtools)
devtools::install_git("https://gitup.uni-potsdam.de/macroecology/mecofun.git")
```

Now, you can load the package and try out the function. Also, check out the help pages for `?select07`.

```{r}
library(mecofun)

# Run select07()
var_sel <- select07(X=UK_birdrichness_clim[,-c(1:3)], 
                    y=UK_birdrichness_clim$richness, 
                    threshold=0.7, family='poisson')

# Check out the structure of the resulting object:
str(var_sel)

# We extract the names of the weakly correlated predictors ordered by the univariate variable importance in terms of AIC:
(pred_sel <- var_sel$pred_sel)
```

So, we have now reduced our set of 19 bioclimatic variables to 6 predictors that are only weakly correlated. Now, we need to decide whether all of these should be included in the final model, or if we select only a few, for example the two most important variables in terms of univariate AIC. As a rule of thumb, we should have ten data points per parameter fitted in the model [@Guisan2017]. We have a large data set and should have no sample size problems.

```{r}
# How many data points do we have?
nrow(UK_birdrichness_clim)
```

## Model selection 
Now that we have selected a set of weakly correlated variables, we can fit the full model and then simplify it by stepwise variable selection using the `step()`function. This stepwise selection tests whether the model in terms of AIC is improved by removing predictors. We consider linear and quadratic terms using `poly()` function. This means that the linear and quadratic terms are not separated in stepwise variable selection. 

```{r}
# Fit the full model:
m_full <- glm( richness ~ poly(bio5,2) + poly(bio15,2) + poly(bio9,2) + poly(bio6,2) + poly(bio8,2) + poly(bio3,2), 
               family='poisson', data=UK_birdrichness_clim)

# Inspect the model:
summary(m_full)
```

How much deviance is explained by our model? As explained earlier, we can calculate explained deviance by quantifying how closely the model predictions fit the data in relation to the null model predictions. Conveniently, the deviance and null deviance can be extracted from the model output. 

```{r message=F, warning=F}
# Explained deviance:
1 - deviance(m_full)/m_full$null.deviance
```

We now simplify the model by using AIC-based stepwise variable selection.

```{r results='hide'}
m_step <- step(m_full)
```

In this case, the full model seems to be the best.

<div class="alert alert-info">
_**Exercise:**_

Repeat the model selection using the `I()`specification of quadratic terms in the full model, meaning the formula should look like `richness ~ bio5 + I(bio5^2) + bio15 + I(bio15^2) +  ...`
</div>


## Model diagnostics

As in ordinary regression we should check whether our model assumptions are met. In GLMs, one important assumption is that the dispersion parameter is taken to be one. The Poisson distribution assumes that mean and variance are equal. The dispersion factor indicates whether the variance is larger than the mean (overdispersion) or smaller than the mean (underdispersion). We can calculate the dispersion factor from the model output by dividing the residual deviance by the residual degrees of freedom.

```{r}
# Dispersion factor
deviance(m_full)/m_full$df.residual
```

The dispersion factor is clearly above 1 and, thus, our model is overdispersed. A potential problem with overdispersion is that the estimated standard errors around the parameter values are often too small resulting in misleading significance levels [@Dormann2013a]. 

One way to deal with this is to use a different error distribution. For example, the negative binomial distribution also adequately describes count data, but allows a variable dispersion factor to be fitted.

```{r}
# Fit the full model with nbinom family:
library(MASS)
m_full2 <- glm.nb( richness ~ poly(bio5,2) + poly(bio15,2) + poly(bio9,2) + poly(bio6,2) + poly(bio8,2) + poly(bio3,2), 
               data=UK_birdrichness_clim)

# Inspect the model:
summary(m_full2)
```

The negative binomial distribution leads to much lower overdispersion and seems to more adequately describe the data. Also, several coefficients have lower significance levels (higher p values) than previously. We thus repeat the stepwise variable selection.

```{r}
m_step2 <- step(m_full2)
```

This time, a reduced model without bio8 seems to be most adequate.

```{r echo=F, eval=F}
# We quickly check that the underlying assumptions of the GLMs are met, for example that there are no systematic patterns in the residuals. The `DHARMa` package provides easy diagnostics for different regression model types.

# If you haven not yet done so, install the package DHARMa first
libary(DHARMa)

# Simulate residuals and plot qq-plot and residuals
simulationOutput <- simulateResiduals(fittedModel = m_full, plot = F)
plot(simulationOutput)

plotResiduals(simulationOutput, form =UK_birdrichness_clim$bio3)

```

## Model assessment

We assess model response to understand the richness-energy relationships, and predictive accuracy.

### Response curves

We plot the response along each climatic gradient while keeping all other gradients constant at their mean. We call this ***partial response plots***. For simplicity, we can use the function `partial_response()` from the `mecofun` package for plotting.

```{r}
# Names of predictors
my_preds <- c('bio5','bio15','bio9','bio6','bio3')

par(mfrow=c(2,3))
partial_response(m_step2, predictors = UK_birdrichness_clim[,my_preds],ylim=c(0,100), ylab='Species richness')
```

We also plot predicted richness against observed richness. Often, richness regressions pull the response towards the mean and by that overpredict low species richness sites and underpredict high species richness sites [@Zurell2016a; @Zurell2020].

```{r}
plot(UK_birdrichness_clim$richness, m_step2$fitted.values, pch=19, col='grey55',xlab='Observed richness', ylab='Predicted richness', xlim=c(0,100), ylim=c(0,100))
abline(0,1, lty='dashed',lwd=2)
abline(lm(m_step2$fitted.values ~ UK_birdrichness_clim$richness), col='darkgreen', lwd=2)
```


### Prediction accuracy

We calculate the C-index, which is a generalisation of the AUC and quantifies the probability that the ranking of pairs of predictions matches the rankings of the observations used for testing [@Briscoe2021].

The C-index is calculated for both training data and 5-fold cross-validated data.

```{r message=F, warning=F}
# We create 5 folds for our data
folds <- dismo::kfold(UK_birdrichness_clim, k = 5)

# Make cross-validated predictions
preds_cv <- crossvalSDM(m_step2, traindat = UK_birdrichness_clim, colname_species = 'richness', colname_pred = my_preds, kfold=folds)

# Calculate C-index
library(Hmisc)
# On training data
rcorr.cens(m_step2$fitted.values, UK_birdrichness_clim$richness)[1]

# On cross-validated data
rcorr.cens(preds_cv, UK_birdrichness_clim$richness)[1]
```

The C-index looks very similar between predictions on training data and on cross-validation folds. It indicates that if we take two random observations from  our data, then in 70% of the cases we would correctly predict a higher abundance (rank) for the larger observed count. 

## Model predictions

Finally, we make predictions in space. For this, we first load the climate layers from last session and then make predictions to these layers.

```{r}
library(raster)

# Load climate data
clim <- stack('data/UK_bioclim.grd')

# Prepare climate data frames
clim_df <- data.frame(rasterToPoints(clim))

# Make predictions
# Make continuous predictions:
clim_df$pred_richness <- predict(m_step2, newdata= clim_df, type="response")
head(clim_df)

# Make raster of predictions to current environment:
r_pred_richness <- rasterFromXYZ(clim_df[,c('x','y','pred_richness')])
plot(r_pred_richness, axes=F, main='Predicted species richness')

```

<div class="alert alert-info">
_**Exercise:**_

Use the data *UK_BBatlas_1968_2008.csv* from last session and calculate a richness regression model for another time period (60s or 80s). Compare response curves and predictions. 
</div>


# References