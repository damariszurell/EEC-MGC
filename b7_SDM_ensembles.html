<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>SDM ensembles</title>

<script src="site_libs/header-attrs-2.25/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/clipboard-1.7.1/clipboard.min.js"></script>
<link href="site_libs/primer-tooltips-1.4.0/build.css" rel="stylesheet" />
<link href="site_libs/klippy-0.0.0.9500/css/klippy.min.css" rel="stylesheet" />
<script src="site_libs/klippy-0.0.0.9500/js/klippy.min.js"></script>
<link href="site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Macroecology and global change</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Pracs: macroecological analyses
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="a0_setup.html">0. Getting started</a>
    </li>
    <li>
      <a href="a1_SpatialData.html">1. Spatial data in R</a>
    </li>
    <li>
      <a href="a2_RichnessGradients.html">2. Species richness gradients</a>
    </li>
    <li>
      <a href="a3_RichnessRegression.html">3. Species richness regression</a>
    </li>
    <li>
      <a href="a4_RangeMaps.html">4. Species range maps</a>
    </li>
    <li>
      <a href="a5_SpeciesThreats.html">5. Species threats</a>
    </li>
    <li>
      <a href="a6_BiodivChanges.html">6. Analysing biodiversity changes</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Pracs: species distribution modelling
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="b1_SpeciesData.html">1. Species data</a>
    </li>
    <li>
      <a href="b2_EnvData.html">2. Environmental data</a>
    </li>
    <li>
      <a href="b3_SDM_intro.html">3. SDMs: simple model fitting</a>
    </li>
    <li>
      <a href="b4_SDM_eval.html">4. SDMs: assessment and prediction</a>
    </li>
    <li>
      <a href="b5_pseudoabsence.html">5. Pseudo-absence and background data</a>
    </li>
    <li>
      <a href="b6_SDM_algorithms.html">6. SDMs: algorithms</a>
    </li>
    <li>
      <a href="b7_SDM_ensembles.html">7. SDMs: ensembles</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://www.uni-potsdam.de/en/ibb-macroecology/index">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li>
  <a href="https://twitter.com/ZurellLab">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">SDM ensembles</h1>

</div>


<script>
  addClassKlippyTo("pre.r, pre.markdown");
  addKlippy('right', 'top', 'auto', '1', 'Copy code', 'Copied!');
</script>
<div class="alert alert-info">
<p><strong>RStudio project</strong></p>
<p>Open the RStudio project that we created in the first session. I
recommend to use this RStudio project for the entire course and within
the RStudio project create separate R scripts for each session.</p>
<ul>
<li>Create a new empty R script by going to the tab “File”, select “New
File” and then “R script”</li>
<li>In the new R script, type <code># Session b7: SDM ensembles</code>
and save the file in your folder “scripts” within your project folder,
e.g. as “b7_SDM_ensembles.R”</li>
</ul>
</div>
<div id="introduction" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>In the previous session, we got to know several SDM algorithms <span
class="citation">(Elith et al. 2006; Thuiller et al. 2009; Guisan,
Thuiller, and Zimmermann 2017)</span>. But how do we proceed with all
these models now? In the end, it would be handy to just work with a
single, general prediction. One way to achive a single prediction would
be to select the best performing algorithm. However, we have also seen
that different models make different assumptions and extrapolate
differently to new environments. <em>A priori</em>, it is difficult to
judge which of the algorithms will perform best in new situations.
Ensemble models have been introduced as an alternative <span
class="citation">(Araujo and New 2007)</span>. These combine different
models and provide information about the overall trend and the
uncertainty around this trend <span class="citation">(Guisan, Thuiller,
and Zimmermann 2017; Thuiller et al. 2019)</span>. Sometimes, the term
ensembles is used synonymously with model averaging <span
class="citation">(Dormann et al. 2018)</span> when only different model
algorithms are combined. According to <span class="citation">Araujo and
New (2007)</span>, ensembles could also take into account varying
initial and boundary conditions (e.g. different data inputs, and
different future scenarios).</p>
<p>In ensembles, predictions can be combined or averaged in different
ways <span class="citation">(Thuiller et al. 2009)</span>. Simple
averages of predictions are derived using the arithmetic mean or the
median. An alternative is to use weighted averages. Here, each model
receives a weight derived from information criteria (e.g. AIC) or from
predictive performance (e.g. AUC or TSS derived from cross-validation or
split-sample approaches). To assess uncertainty in model predictions, we
can, for example, calculate the coefficient of variation or standard
deviation.</p>
<p>Here, we will concentrate on how different algorithms can be combined
into ensemble predictions. This is primarily meant to show you the main
workflow. The ensembles can be adopted individually by using less, more
or simply other algorithms, by using different parameterisations for the
different algorithms, by using different input data (e.g. atlas data
vs. range maps), and projections can be made to different scenarios of
future (or past) global change.</p>
<p>There is one important note for forecast ensembles. Typically, we
would make projections under climate change or land use change for
scenarios derived from different climate models or land use models. This
captures the uncertainty from different underlying model assumptions.
This should not be confused with different storylines (the old SRES
storylines or newer RCPs in climate models, or the SSPs in land use
models; <span class="citation">Vuuren and Carter (2013)</span>). When
making projections into the future, we would typically combine ensembles
of predictions for different SDM algorithms and different climate and
land use models. However, we would not combine projections for different
storylines, but would want to analyse the potential pathways
separately.</p>
</div>
<div id="recap-of-last-session-data-and-model-building-steps"
class="section level1" number="2">
<h1><span class="header-section-number">2</span> Recap of last session:
data and model building steps</h1>
<p>We will continue to work on the Yellowhammer example of the previous
session, using data from the British breeding and wintering birds
citizen science atlas <span class="citation">(Gillings et al.
2019)</span>. The species presense/absence data and the bioclimatic
variables at these locations are available from file. Also, we have
already tested the data for multicollinearity and identified bio12 and
bio9 as most important but weakly correlated variables, and we have run
different algorithms.</p>
<div id="data" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Data</h2>
<pre class="r"><code>library(terra)

bg &lt;- terra::rast(&#39;data/Prac3_UK_mask.grd&#39;)
sp_dat &lt;- read.table(&#39;data/Prac3_YellowHammer.txt&#39;,header=T)</code></pre>
<p>Previously, we have used a simple split-sample to validate model
performance:</p>
<pre class="r"><code># Read the split-sample back in
train_i &lt;- scan(&#39;data/indices_traindata.txt&#39;)

# Then, we can subset the training and testing data
sp_train &lt;- sp_dat[train_i,]
sp_test &lt;- sp_dat[-train_i,]</code></pre>
<p>For making predictions in space, we also load the previously
processed raster layers of current climate (see session 4).</p>
<pre class="r"><code>bio_curr &lt;- terra::rast(&#39;data/Prac4_UK_bio_curr.grd&#39;)</code></pre>
</div>
<div id="model-fitting" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Model fitting</h2>
<p>In the previous tutorial, we already fitted different model
algorithms. Here, we refit them very quickly.</p>
<pre class="r"><code># Our predictors, for simplicity we only use two:
my_preds &lt;- c(&#39;bio12&#39;, &#39;bio9&#39;)


library(dismo)

# Fit BIOCLIM model - with Raster* object!
m_bc &lt;- bioclim(stack(bio_curr[[my_preds]]), 
                sp_train[sp_train$Emberiza_citrinella==1,c(&#39;EASTING&#39;,&#39;NORTHING&#39;)])

# Fit Domain model - with Raster* object!
m_dom &lt;- domain(stack(bio_curr[[my_preds]]), 
                sp_train[sp_train$Emberiza_citrinella==1,c(&#39;EASTING&#39;,&#39;NORTHING&#39;)])

# Fit generalised linear model (GLM)
m_glm &lt;- step(glm( Emberiza_citrinella ~ bio12 + I(bio12^2) + bio9 + I(bio9^2),
    family=&#39;binomial&#39;, data=sp_train))

# Fit generalised additive model (GAM) with cubic smoothing splines
library(mgcv)
m_gam &lt;- mgcv::gam( Emberiza_citrinella ~ s(bio12, k=4) + s(bio9, k=4),
    family=&#39;binomial&#39;, data=sp_train)

# Fit Maxent
library(maxnet)
m_maxent &lt;- maxnet(p=sp_train$Emberiza_citrinella, data=sp_train[,my_preds],
    maxnet.formula(p=sp_train$Emberiza_citrinella, data=sp_train[,my_preds], classes=&quot;lh&quot;))

# Fit classification and regression tree (CART)
library(rpart)
m_cart &lt;- rpart( Emberiza_citrinella ~ bio12 + bio9,
    data=sp_train, control=rpart.control(minsplit=20,xval=10))

# Fit Random Forest (RF)
library(randomForest)
m_rf &lt;- randomForest( x=sp_train[,my_preds], y=sp_train$Emberiza_citrinella, 
    ntree=1000, importance =T)

# Fit boosted regression tree (BRT)
library(gbm)
m_brt &lt;- gbm.step(data = sp_train, 
    gbm.x = my_preds,
    gbm.y = &#39;Emberiza_citrinella&#39;, 
    family = &#39;bernoulli&#39;,
    tree.complexity = 2,
    bag.fraction = 0.75,
    learning.rate = 0.001,
    verbose=F,
    plot.main=F)</code></pre>
</div>
<div id="model-assessment" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Model assessment</h2>
<p>We have already validated model performance on the hold-out test data
in last session, and stored the results of the model validation:</p>
<pre class="r"><code># Adapt the file path to your folder structure
(comp_perf &lt;- read.table(&#39;data/SDM_alg_performances.txt&#39;, header=T))</code></pre>
<pre><code>##      alg       AUC       TSS     Kappa      Sens      Spec       PCC
## 1     bc 0.7579365 0.4017857 0.4090909 0.5476190 0.8541667 0.7111111
## 2    dom 0.7098214 0.3601190 0.3655589 0.5476190 0.8125000 0.6888889
## 3    glm 0.8903770 0.7172619 0.7119645 0.9047619 0.8125000 0.8555556
## 4    gam 0.8859127 0.7172619 0.7119645 0.9047619 0.8125000 0.8555556
## 5   cart 0.8196925 0.5922619 0.5958084 0.7380952 0.8541667 0.8000000
## 6     rf 0.8338294 0.6458333 0.6439169 0.8333333 0.8125000 0.8222222
## 7    brt 0.8831845 0.7172619 0.7119645 0.9047619 0.8125000 0.8555556
## 8 maxent 0.8774802 0.7172619 0.7119645 0.9047619 0.8125000 0.8555556
##            D2 thresh
## 1 -0.37385682  0.175
## 2  0.09900221  0.680
## 3  0.37029784  0.525
## 4  0.36548148  0.530
## 5  0.16934395  0.800
## 6  0.16438501  0.615
## 7  0.34949617  0.580
## 8  0.25816707  0.410</code></pre>
</div>
<div id="predictions" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Predictions</h2>
<p>We also know how to make predictions to independent test data:</p>
<pre class="r"><code>pred_testdata &lt;- data.frame(
  bc = predict(m_bc, sp_test[,my_preds]),
  dom = predict(m_dom, sp_test[,my_preds]),
  glm = predict(m_glm, sp_test[,my_preds], type=&#39;response&#39;),
  gam = as.vector(predict(m_gam, sp_test[,my_preds], type=&#39;response&#39;)),
  cart = predict(m_cart, sp_test[,my_preds]),
  rf = predict(m_rf, sp_test[,my_preds], type=&#39;response&#39;),
  brt = predict.gbm(m_brt, sp_test[,my_preds], 
                         n.trees=m_brt$gbm.call$best.trees, type=&quot;response&quot;),
  maxent = predict(m_maxent, sp_test[,my_preds], type=&quot;logistic&quot;)
)

summary(pred_testdata)</code></pre>
<pre><code>##        bc               dom              glm                 gam           
##  Min.   :0.00000   Min.   :0.0000   Min.   :0.0009634   Min.   :0.0007748  
##  1st Qu.:0.02101   1st Qu.:0.4422   1st Qu.:0.1988715   1st Qu.:0.1921130  
##  Median :0.11765   Median :0.6294   Median :0.5515085   Median :0.5796006  
##  Mean   :0.21083   Mean   :0.5440   Mean   :0.4999623   Mean   :0.5007960  
##  3rd Qu.:0.33193   3rd Qu.:0.7012   3rd Qu.:0.8040124   3rd Qu.:0.8025983  
##  Max.   :0.94118   Max.   :0.7329   Max.   :0.9070566   Max.   :0.9005589  
##       cart               rf                 brt             maxent       
##  Min.   :0.02273   Min.   :0.0003333   Min.   :0.1193   Min.   :0.01877  
##  1st Qu.:0.20000   1st Qu.:0.1284375   1st Qu.:0.1769   1st Qu.:0.22899  
##  Median :0.75000   Median :0.5960833   Median :0.5961   Median :0.43513  
##  Mean   :0.52357   Mean   :0.5107167   Mean   :0.5108   Mean   :0.37117  
##  3rd Qu.:0.85047   3rd Qu.:0.8444583   3rd Qu.:0.8070   3rd Qu.:0.54487  
##  Max.   :0.85047   Max.   :0.9760833   Max.   :0.8191   Max.   :0.58623</code></pre>
<p>As we have stored the maxSens+Spec threshold for each model, we can
also threshold the predictions to obtain predicted presences and
absences.</p>
<pre class="r"><code># We use the sapply function to apply the thresholding to all columns 
# in the prediction data frame. You could also use a loop or construct
# the data frame by hand.
binpred_testdata &lt;- sapply(names(pred_testdata), 
                           FUN=function(alg){
                              ifelse(pred_testdata[,alg] &gt;= comp_perf[comp_perf$alg==alg,&#39;thresh&#39;],1,0)
                             }
                           )

summary(binpred_testdata)</code></pre>
<pre><code>##        bc              dom              glm              gam        
##  Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  
##  Median :0.0000   Median :0.0000   Median :1.0000   Median :1.0000  
##  Mean   :0.3333   Mean   :0.3556   Mean   :0.5222   Mean   :0.5222  
##  3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  
##  Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  
##       cart              rf              brt             maxent      
##  Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  
##  Median :0.0000   Median :0.0000   Median :1.0000   Median :1.0000  
##  Mean   :0.4222   Mean   :0.4889   Mean   :0.5222   Mean   :0.5222  
##  3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  
##  Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000</code></pre>
</div>
</div>
<div id="making-ensembles" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Making ensembles</h1>
<p>We have gathered all information now that we need for making
ensembles: evaluation statistics, optimal thresholds for binary
predictions, and model predictions. The predictions can be combined into
ensembles in different ways:<br />
- mean of probabilities<br />
- median of probabilities<br />
- weighted mean of probabilities (weighted by model performance)<br />
- committee averaging of binary predictions (what is the proportion of
models predicting a presence?)</p>
<pre class="r"><code># Mean of probabilities
mean_prob &lt;- rowMeans(pred_testdata)

# Median of probabilities
median_prob &lt;- apply(pred_testdata, 1, median)

# Weighted mean of probabilities, weighted by TSS 
# (Make sure that order of models is the same in df for predictions and performance!!)
wmean_prob &lt;- apply(pred_testdata, 1, weighted.mean, w=comp_perf[,&#39;TSS&#39;])

# Committee averaging of binary predictions: calculates the proportion of
# models that predict the species to be present.
committee_av &lt;- rowSums(binpred_testdata)/ncol(binpred_testdata)

# We can also calculate uncertainty measures, 
# e.g. the standard deviation when making ensembles of mean probabilities.
sd_prob &lt;- apply(pred_testdata, 1, sd)</code></pre>
<p>Thus, ensembles can be easily constructed by hand. Of course, if you
have many input data, models, and scenarios to put into your ensemble,
this is easily becoming tedious. For that purpose, it will be very
useful to automatise your code and write automatic functions. For an
example for automatising your functions, have a look at the code that we
published along with <span class="citation">Zurell et al. (2020)</span>,
which you can obtain from the corresponding <a
href="https://github.com/damariszurell/SSDM-JSDM">github repository</a>.
Also, there are packages like <code>biomod2</code> that make it easy to
construct ensembles automatically <span class="citation">(Thuiller et
al. 2009)</span>.</p>
<p>Now, let’s assess the performance of these ensembles.</p>
<pre class="r"><code>library(mecofun)

# performance measures for &quot;mean of probabilities&quot;
(perf_mean_prob &lt;- evalSDM(sp_test$Emberiza_citrinella, mean_prob))</code></pre>
<pre><code>##         AUC       TSS     Kappa      Sens      Spec       PCC        D2 thresh
## 1 0.8759921 0.6904762 0.6884273 0.8571429 0.8333333 0.8444444 0.3223481   0.53</code></pre>
<pre class="r"><code># performance measures for &quot;median of probabilities&quot;:
(perf_median_prob &lt;- evalSDM(sp_test$Emberiza_citrinella, median_prob))</code></pre>
<pre><code>##         AUC       TSS     Kappa      Sens      Spec       PCC        D2 thresh
## 1 0.8824405 0.7380952 0.7337278 0.9047619 0.8333333 0.8666667 0.3492227   0.55</code></pre>
<pre class="r"><code># performance measures for &quot;weighted mean of probabilities&quot;:
(perf_wmean_prob &lt;- evalSDM(sp_test$Emberiza_citrinella, wmean_prob))</code></pre>
<pre><code>##         AUC       TSS     Kappa      Sens      Spec       PCC        D2 thresh
## 1 0.8784722 0.6964286 0.6902655 0.9047619 0.7916667 0.8444444 0.3325669    0.5</code></pre>
<pre class="r"><code># performance measures for &quot;committee average&quot;:
(perf_committee_prob &lt;- evalSDM(sp_test$Emberiza_citrinella, committee_av))</code></pre>
<pre><code>##        AUC       TSS     Kappa      Sens   Spec       PCC        D2 thresh
## 1 0.875744 0.7172619 0.7119645 0.9047619 0.8125 0.8555556 -0.213853  0.435</code></pre>
<pre class="r"><code># Compare:
(ens_perf &lt;- rbind(mean_prob = perf_mean_prob, median_prob = perf_median_prob, 
                    wmean_prob = perf_mean_prob, committee_av = perf_committee_prob))</code></pre>
<pre><code>##                    AUC       TSS     Kappa      Sens      Spec       PCC
## mean_prob    0.8759921 0.6904762 0.6884273 0.8571429 0.8333333 0.8444444
## median_prob  0.8824405 0.7380952 0.7337278 0.9047619 0.8333333 0.8666667
## wmean_prob   0.8759921 0.6904762 0.6884273 0.8571429 0.8333333 0.8444444
## committee_av 0.8757440 0.7172619 0.7119645 0.9047619 0.8125000 0.8555556
##                      D2 thresh
## mean_prob     0.3223481  0.530
## median_prob   0.3492227  0.550
## wmean_prob    0.3223481  0.530
## committee_av -0.2138530  0.435</code></pre>
<div id="visualising-response-surfaces" class="section level2"
number="3.1">
<h2><span class="header-section-number">3.1</span> Visualising response
surfaces</h2>
<p>Let’s plot the response surfaces for the ensembles.</p>
<pre class="r"><code>library(RColorBrewer)
library(lattice)

cls &lt;- colorRampPalette(rev(brewer.pal(11, &#39;RdYlBu&#39;)))(100)

# We prepare our grid of environmental predictors:
xyz &lt;- expand.grid(
    seq(min(sp_train[,my_preds[1]]),max(sp_train[,my_preds[1]]),length=50),
    seq(min(sp_train[,my_preds[2]]),max(sp_train[,my_preds[2]]),length=50))
names(xyz) &lt;- my_preds

# Make predictions of all models:
xyz_preds &lt;- data.frame(
  bc = predict(m_bc, xyz),
  dom = predict(m_dom, xyz),
  glm = predict(m_glm, xyz, type=&#39;response&#39;),
  gam = predict(m_gam, xyz[,my_preds], type=&#39;response&#39;),
  cart = predict(m_cart, xyz),
  rf = predict(m_rf, xyz, type=&#39;response&#39;),
  brt = predict.gbm(m_brt, xyz, 
                         n.trees=m_brt$gbm.call$best.trees, type=&quot;response&quot;),
  maxent = predict(m_maxent, xyz, type=&quot;logistic&quot;)
)

# Make binary predictions
xyz_bin &lt;- sapply(names(xyz_preds), FUN=function(alg){ 
  ifelse(xyz_preds[,alg]&gt;=comp_perf[comp_perf$alg==alg,&#39;thresh&#39;],1,0)
})

# Make ensembles:
xyz_ensemble &lt;- data.frame(
  mean_prob = rowMeans(xyz_preds),
  median_prob = apply(xyz_preds, 1, median),
  wmean_prob = apply(xyz_preds, 1, weighted.mean, w=comp_perf[,&#39;TSS&#39;]),
  committee_av = rowSums(xyz_bin)/ncol(xyz_bin),
  sd_prob = apply(xyz_preds, 1, sd)
)   

# Plot ensemble of mean probabilities:
xyz$z &lt;- xyz_ensemble[,&#39;mean_prob&#39;]
wireframe(z ~ bio12 + bio9, data = xyz, zlab = list(&quot;Occurrence prob.&quot;, rot=90), 
          drape = TRUE, col.regions = cls, scales = list(arrows = FALSE), 
          zlim = c(0, 1), main=&#39;Ensemble: mean prob&#39;, xlab=&#39;bio12&#39;, 
          ylab=&#39;bio9&#39;, screen=list(z = -120, x = -70, y = 3))</code></pre>
<p><img src="b7_SDM_ensembles_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<pre class="r"><code># Plot ensemble of median probabilities:
xyz$z &lt;- xyz_ensemble[,&#39;median_prob&#39;]
wireframe(z ~ bio12 + bio9, data = xyz, zlab = list(&quot;Occurrence prob.&quot;, rot=90), 
          drape = TRUE, col.regions = cls, scales = list(arrows = FALSE), 
          zlim = c(0, 1), main=&#39;Ensemble: median prob&#39;, xlab=&#39;bio12&#39;, 
          ylab=&#39;bio9&#39;, screen=list(z = -120, x = -70, y = 3))</code></pre>
<p><img src="b7_SDM_ensembles_files/figure-html/unnamed-chunk-12-2.png" width="672" /></p>
<pre class="r"><code># Plot ensemble of weighted mean probabilities:
xyz$z &lt;- xyz_ensemble[,&#39;wmean_prob&#39;]
wireframe(z ~ bio12 + bio9, data = xyz, zlab = list(&quot;Occurrence prob.&quot;, rot=90), 
          drape = TRUE, col.regions = cls, scales = list(arrows = FALSE), 
          zlim = c(0, 1), main=&#39;Ensemble: weighted mean prob&#39;, xlab=&#39;bio12&#39;, 
          ylab=&#39;bio9&#39;, screen=list(z = -120, x = -70, y = 3))</code></pre>
<p><img src="b7_SDM_ensembles_files/figure-html/unnamed-chunk-12-3.png" width="672" /></p>
<pre class="r"><code># Plot ensemble of committee average:
xyz$z &lt;- xyz_ensemble[,&#39;committee_av&#39;]
wireframe(z ~ bio12 + bio9, data = xyz, zlab = list(&quot;Occurrence prob.&quot;, rot=90), 
          drape = TRUE, col.regions = cls, scales = list(arrows = FALSE), 
          zlim = c(0, 1), main=&#39;Ensemble: committee average&#39;, xlab=&#39;bio12&#39;, 
          ylab=&#39;bio9&#39;, screen=list(z = -120, x = -70, y = 3))</code></pre>
<p><img src="b7_SDM_ensembles_files/figure-html/unnamed-chunk-12-4.png" width="672" /></p>
<pre class="r"><code># Plot standard deviation of mean probabilities. This gives us an indication where in environmental space we have highest uncertainty:
xyz$z &lt;- xyz_ensemble[,&#39;sd_prob&#39;]
wireframe(z ~ bio12 + bio9, data = xyz, zlab = list(&quot;Occurrence prob.&quot;, rot=90), 
          drape = TRUE, col.regions = cls, scales = list(arrows = FALSE), 
          zlim = c(0, 1), main=&#39;Ensemble: sd&#39;, xlab=&#39;bio12&#39;, ylab=&#39;bio9&#39;, 
          screen=list(z = -120, x = -70, y = 3))</code></pre>
<p><img src="b7_SDM_ensembles_files/figure-html/unnamed-chunk-12-5.png" width="672" /></p>
</div>
<div id="mapping-ensemble-predictions" class="section level2"
number="3.2">
<h2><span class="header-section-number">3.2</span> Mapping ensemble
predictions</h2>
<p>Finally, let’s do some mapping. We first map the occurrence
probabilities predicted by the different algorithms as well as the
potential presences.</p>
<pre class="r"><code># Prepare data frame with environmental data
bio_curr_df &lt;- data.frame(crds(bio_curr[[my_preds]]),as.points(bio_curr[[my_preds]]))

# We make predictions of all models:
env_preds &lt;- data.frame(bio_curr_df[,1:2], 
  bc = predict(m_bc, bio_curr_df),
  dom = predict(m_dom, bio_curr_df),
  glm = predict(m_glm, bio_curr_df, type=&#39;response&#39;),
  gam = predict(m_gam, bio_curr_df[,my_preds], type=&#39;response&#39;),
  cart = predict(m_cart, bio_curr_df),
  rf = predict(m_rf, bio_curr_df, type=&#39;response&#39;),
  brt = predict.gbm(m_brt, bio_curr_df, 
                         n.trees=m_brt$gbm.call$best.trees, type=&quot;response&quot;),
  maxent = predict(m_maxent, bio_curr_df, type=&quot;logistic&quot;))
                        

# Binarise predictions of all algorithms
env_preds_bin &lt;- data.frame(bio_curr_df[,1:2],
  sapply(names(env_preds[,-c(1:2)]), FUN=function(alg){ 
    ifelse(env_preds[,alg]&gt;=comp_perf[comp_perf$alg==alg,&#39;thresh&#39;],1,0)
  }))

# Make SpatRasters from predictions:
r_preds &lt;- terra::rast(env_preds, crs=crs(bg))
r_preds_bin &lt;- terra::rast(env_preds_bin, crs=crs(bg))

# Map predicted occurrence probabilities:
library(ggplot2)</code></pre>
<pre><code>## 
## Attaching package: &#39;ggplot2&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:randomForest&#39;:
## 
##     margin</code></pre>
<pre class="r"><code>library(tidyterra)</code></pre>
<pre><code>## 
## Attaching package: &#39;tidyterra&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:raster&#39;:
## 
##     select</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     filter</code></pre>
<pre class="r"><code>ggplot() +
  geom_spatraster(data = r_preds) +
  facet_wrap(~lyr, ncol = 4) +
 scale_fill_whitebox_c(
    palette = &quot;muted&quot;
  ) +
  labs(fill = &quot;Occ. prob.&quot;)</code></pre>
<p><img src="b7_SDM_ensembles_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<pre class="r"><code># Map predicted presences:
ggplot() +
  geom_spatraster(data = r_preds_bin) +
  facet_wrap(~lyr, ncol = 4) +
 scale_fill_whitebox_c(
    direction=-1,
    guide = guide_legend(reverse = TRUE),
     n.breaks=2
  ) +
  labs(fill = &quot;Predicted \npresence&quot;)</code></pre>
<p><img src="b7_SDM_ensembles_files/figure-html/unnamed-chunk-13-2.png" width="672" /></p>
<p>Now, we map the ensemble predictions.</p>
<pre class="r"><code># We make ensembles:    
env_ensemble &lt;- data.frame(bio_curr_df[,1:2], 
  mean_prob = rowMeans(env_preds[,-c(1:2)]),
  median_prob = apply(env_preds[,-c(1:2)], 1, median),
  wmean_prob = apply(env_preds[,-c(1:2)], 1, weighted.mean, w=comp_perf[,&#39;TSS&#39;]),
  committee_av = rowSums(env_preds_bin[,-c(1:2)])/ncol(env_preds_bin[,-c(1:2)]),
  sd_prob = apply(env_preds[,-c(1:2)], 1, sd))

# Make SpatRasters from ensemble predictions:
r_ens &lt;- terra::rast(env_ensemble, crs=crs(bg))

# Map continuous ensemble predictions:
ggplot() +
  geom_spatraster(data = r_ens[[1:4]]) +
  facet_wrap(~lyr, ncol = 4) +
 scale_fill_whitebox_c(
    palette = &quot;muted&quot;
  ) +
  labs(fill = &quot;Occ. prob.&quot;)</code></pre>
<p><img src="b7_SDM_ensembles_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Mapping the standard deviation of model predictions shows us the
areas of highest deviation between model algorithms.</p>
<pre class="r"><code># Map standard deviation across model algorithms:
plot(r_ens[[&#39;sd_prob&#39;]])</code></pre>
<p><img src="b7_SDM_ensembles_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>We can also derive binary ensemble predictions. We have already
estimated the optimal thresholds when calculating the performance
measures for the ensembles.</p>
<pre class="r"><code># Binarise ensemble predictions
env_ensemble_bin &lt;- data.frame(bio_curr_df[,1:2], 
    sapply(c(&#39;mean_prob&#39;, &#39;median_prob&#39;, &#39;wmean_prob&#39;), 
           FUN=function(x){ifelse(env_ensemble[,x]&gt;= ens_perf[x,&#39;thresh&#39;],1,0)}))

# Make SpatRasters:
r_ens_bin &lt;- terra::rast(env_ensemble_bin, crs=crs(bg))

# Map predicted presence from ensembles:
ggplot() +
  geom_spatraster(data = r_ens_bin) +
  facet_wrap(~lyr, ncol = 3) +
 scale_fill_whitebox_c(
    direction=-1,
    guide = guide_legend(reverse = TRUE),
     n.breaks=2
  ) +
  labs(fill = &quot;Predicted \npresence&quot;)</code></pre>
<p><img src="b7_SDM_ensembles_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<div class="alert alert-info">
<p><em><strong>Exercise:</strong></em></p>
<p>In the previous practical, you ran three different SDM algorithms on
your own species-climate data (from practical b5). Use these to
construct ensembles.</p>
</div>
</div>
</div>
<div id="further-analysing-your-predictions" class="section level1"
number="4">
<h1><span class="header-section-number">4</span> Further analysing your
predictions</h1>
<p>Congratulations. You have successfully fitted multiple SDM algorithms
to your species distribution data and made predictions in space and
time. Of course, science doesn’t stop here and you may want to answer
different questions using your SDM. I only provide some hints here.</p>
<div class="alert alert-success">
<p>Remember how we analysed biodiversity changes in <a
href="a6_BiodivChanges.html">practical a6</a>. The same workflow can be
used to analyse predicted current vs. predicted future ranges.</p>
<ul>
<li>Download a future climate scenario and make future range
predictions.</li>
<li>How much range size is your species predicted to win or lose under
climate change?</li>
<li>Where is your species range predicted to remain stable, to become
unsuitable or to become colonisable under climate change?</li>
</ul>
<p>In conservation, we often aim to prioritise the most important sites
for reserve selection.</p>
<ul>
<li>Identify the top 5 % suitable area (the 5 % of cells with the
highest habitat suitability)</li>
<li>Compare the top 5 % suitable area across different SDM
algorithms</li>
<li>Overlay the top 5 % suitable area for multiple species (if you
fitted SDMs to multiple species)</li>
</ul>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-araujo2007" class="csl-entry">
Araujo, M. B., and M. New. 2007. <span>“Ensemble Forecasting of Species
Distributions.”</span> <em>Trends in Ecology and Evolution</em> 22:
42–47.
</div>
<div id="ref-Dormann2018a" class="csl-entry">
Dormann, C. F., J. M. Calabrese, G. Guillera-Arroita, E. Matechou, V.
Bahn, K. Barton, C. M. Beale, et al. 2018. <span>“Model Averaging in
Ecology: A Review of Bayesian, Information-Theoretic, and Tactical
Approaches for Predictive Inference.”</span> <em>Ecological
Monographs</em> 88 (4): 485–504. <a
href="https://doi.org/10.1002/ecm.1309">https://doi.org/10.1002/ecm.1309</a>.
</div>
<div id="ref-elith2006" class="csl-entry">
Elith, J., C. H. Graham, R. P. Anderson, M. Dudik, S. Ferrier, A.
Guisan, R. J. Hijmans, et al. 2006. <span>“Novel Methods Improve
Prediction of Species’ Distribution from Occurence Data.”</span>
<em>Ecography</em> 29: 129–51.
</div>
<div id="ref-Gillings2019" class="csl-entry">
Gillings, S., D. E. Balmer, B. J. Caffrey, I. S. Downie, D. W. Gibbons,
P. C. Lack, J. B. Reid, J. T. R. Sharrock, R. L. Swann, and R. J.
Fuller. 2019. <span>“Breeding and Wintering Bird Distributions in
Britain and Ireland from Citizen Science Bird Atlases.”</span>
<em>Global Ecology and Biogeography</em> 28 (7): 866–74. <a
href="https://doi.org/10.1111/geb.12906">https://doi.org/10.1111/geb.12906</a>.
</div>
<div id="ref-Guisan2017" class="csl-entry">
Guisan, A., W. Thuiller, and N. E. Zimmermann. 2017. <em>Habitat
Suitability and Distribution Models with Applications in r</em>.
Cambride University Press.
</div>
<div id="ref-Thuiller2019" class="csl-entry">
Thuiller, W., M. Guéguen, J. Renaud, D. N. Karger, and N. E. Zimmermann.
2019. <span>“Uncertainty in Ensembles of Global Biodiversity
Scenarios.”</span> <em>Nature Communications</em> 10: 1446.
</div>
<div id="ref-Thuiller2009" class="csl-entry">
Thuiller, W., B. Lafourcade, R. Engler, and M. B. Araujo. 2009.
<span>“BIOMOD - a Platform for Ensemble Forecasting of Species
Distributions.”</span> <em>Ecography</em> 32: 369–73.
</div>
<div id="ref-Vuuren2013" class="csl-entry">
Vuuren, D. P. van, and T. R. Carter. 2013. <span>“Climate and
Socio-Economic Scenarios for Climate Change Research and Assessment:
Reconciling the New with the Old.”</span> <em>Climatic Change</em> 122
(November): 415–29.
</div>
<div id="ref-Zurell2020" class="csl-entry">
Zurell, D., N. E. Zimmermann, H. Gross, A. Baltensweiler, T. Sattler,
and R. O. Wüest. 2020. <span>“Testing Species Assemblage Predictions
from Stacked and Joint Species Distribution Models.”</span> <em>Journal
of Biogeography</em> 47 (1): 101–13. <a
href="https://doi.org/10.1111/jbi.13608">https://doi.org/10.1111/jbi.13608</a>.
</div>
</div>
</div>

<!DOCTYPE html>
<html>

<br>
<hr />
<div id="footer">
<p>Damaris Zurell 2022 <a href="http://creativecommons.org/licenses/by/4.0/" >(CC BY 4.0)</a>.  </p>
</div>

</html>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
